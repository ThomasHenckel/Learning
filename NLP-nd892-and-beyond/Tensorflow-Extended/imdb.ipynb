{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tghWegsjhpkt"
   },
   "source": [
    "##### Copyright &copy; 2020 The TensorFlow Authors.\n",
    "\n",
    "This is a modified version of the [census](https://github.com/tensorflow/tfx/blob/master/docs/tutorials/transform/census.ipynb) example combining it with the [sentiment_example](https://github.com/tensorflow/transform/blob/master/examples/sentiment_example.py), that trains a text classifier on the IMDB dataset.\n",
    "\n",
    "I have made this to experiment with other data sources, and other network architectures. this is the first step in that allowing text classification based on CSV input data.\n",
    "\n",
    "Plans to extend\n",
    "1. Replace the liniar classifier tf.estimator.LinearClassifier with a RNN, i cant se any prebuild RNN estimatores https://www.tensorflow.org/guide/estimator so properly a custom estimator have to be build\n",
    "2. Extend the example to be a multi-class text classifier, properly using 20 newsgroup dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "rSGJWC5biBiG"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mPt5BHTwy_0F"
   },
   "source": [
    "# Preprocessing data with TensorFlow Transform\n",
    "***The Feature Engineering Component of TensorFlow Extended (TFX)***\n",
    "\n",
    "This example colab notebook provides a somewhat more advanced example of how <a target='_blank' href='https://www.tensorflow.org/tfx/transform/'>TensorFlow Transform</a> (`tf.Transform`) can be used to preprocess data using exactly the same code for both training a model and serving inferences in production.\n",
    "\n",
    "TensorFlow Transform is a library for preprocessing input data for TensorFlow, including creating features that require a full pass over the training dataset.  For example, using TensorFlow Transform you could:\n",
    "\n",
    "* Normalize an input value by using the mean and standard deviation\n",
    "* Convert strings to integers by generating a vocabulary over all of the input values\n",
    "* Convert floats to integers by assigning them to buckets, based on the observed data distribution\n",
    "\n",
    "TensorFlow has built-in support for manipulations on a single example or a batch of examples. `tf.Transform` extends these capabilities to support full passes over the entire training dataset.\n",
    "\n",
    "The output of `tf.Transform` is exported as a TensorFlow graph which you can use for both training and serving. Using the same graph for both training and serving can prevent skew, since the same transformations are applied in both stages.\n",
    "\n",
    "Key Point: In order to understand `tf.Transform` and how it works with Apache Beam, you'll need to know a little bit about Apache Beam itself.  The <a target='_blank' href='https://beam.apache.org/documentation/programming-guide/'>Beam Programming Guide</a> is a great place to start."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RptgLn2RYuK3"
   },
   "source": [
    "## Python check, imports, and globals\n",
    "First we'll make sure that we're using Python 3, and then go ahead and install and import the stuff we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tFcdSuXTidhH"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Confirm that we're using Python 3\n",
    "assert sys.version_info.major is 3, 'Oops, not running Python 3. Use Runtime > Change runtime type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to rain and test data\n",
    "# should be split prior to running this, however here we use same file, and we can't trust the test accuracy\n",
    "train = 'movie_data.csv'\n",
    "test = 'movie_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "K4QXVIM7iglN"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF: 2.1.0\n",
      "Installing Apache Beam\n",
      "Beam: 2.20.0\n",
      "Installing TensorFlow Transform\n",
      "Transform: 0.22.0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "print('TF: {}'.format(tf.__version__))\n",
    "\n",
    "print('Installing Apache Beam')\n",
    "!pip install -Uq apache_beam==2.20.0\n",
    "import apache_beam as beam\n",
    "print('Beam: {}'.format(beam.__version__))\n",
    "\n",
    "print('Installing TensorFlow Transform')\n",
    "!pip install -q tensorflow-transform==0.22.0\n",
    "import tensorflow_transform as tft\n",
    "print('Transform: {}'.format(tft.__version__))\n",
    "\n",
    "import tensorflow_transform.beam as tft_beam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qtTn4at8rurk"
   },
   "source": [
    "### Define our features and schema\n",
    "Let's define a schema based on what types the columns are in our input.  Among other things this will help with importing them correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsr1nLHqyg_"
   },
   "outputs": [],
   "source": [
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "VOCAB_SIZE = 20000\n",
    "\n",
    "REVIEW_KEY = 'text'\n",
    "REVIEW_WEIGHT_KEY = 'review_weight'\n",
    "LABEL_KEY = 'label'\n",
    "\n",
    "RAW_DATA_FEATURE_SPEC = {\n",
    "    REVIEW_KEY: tf.io.FixedLenFeature([], tf.string),\n",
    "    LABEL_KEY: tf.io.FixedLenFeature([], tf.int64)\n",
    "}\n",
    "\n",
    "RAW_DATA_METADATA = dataset_metadata.DatasetMetadata(\n",
    "    schema_utils.schema_from_feature_spec(RAW_DATA_FEATURE_SPEC))\n",
    "\n",
    "DELIMITERS = '.,!?() '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zdXy9lo4t45d"
   },
   "source": [
    "### Setting hyperparameters and basic housekeeping\n",
    "Constants and hyperparameters used for training.  The bucket size includes all listed categories in the dataset description as well as one extra for \"?\" which represents unknown.\n",
    "\n",
    "Note: The number of instances will be computed by `tf.Transform` in future versions, in which case it can be read from the metadata.  Similarly BUCKET_SIZES will not be needed as this information will be stored in the metadata for each of the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WHyOkC9uL71"
   },
   "outputs": [],
   "source": [
    "testing = os.getenv(\"WEB_TEST_BROWSER\", False)\n",
    "if testing:\n",
    "  TRAIN_NUM_EPOCHS = 1\n",
    "  NUM_TRAIN_INSTANCES = 1\n",
    "  TRAIN_BATCH_SIZE = 1\n",
    "  NUM_TEST_INSTANCES = 1\n",
    "else:\n",
    "  TRAIN_NUM_EPOCHS = 16\n",
    "  NUM_TRAIN_INSTANCES = 32561\n",
    "  TRAIN_BATCH_SIZE = 128\n",
    "  NUM_TEST_INSTANCES = 16281\n",
    "\n",
    "# Names of temp files\n",
    "TRANSFORMED_TRAIN_DATA_FILEBASE = 'train_transformed'\n",
    "TRANSFORMED_TEST_DATA_FILEBASE = 'test_transformed'\n",
    "EXPORTED_MODEL_DIR = 'exported_model_dir'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0a1ns5KswDb2"
   },
   "source": [
    "## Preprocessing with `tf.Transform`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "KKd3mCLNVYmg"
   },
   "source": [
    "### Create a `tf.Transform` preprocessing_fn\n",
    "The _preprocessing function_ is the most important concept of tf.Transform. A preprocessing function is where the transformation of the dataset really happens. It accepts and returns a dictionary of tensors, where a tensor means a [`Tensor`](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/Tensor) or [`SparseTensor`](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/SparseTensor). There are two main groups of API calls that typically form the heart of a preprocessing function:\n",
    "\n",
    "1. **TensorFlow Ops:** Any function that accepts and returns tensors, which usually means TensorFlow ops. These add TensorFlow operations to the graph that transforms raw data into transformed data one feature vector at a time.  These will run for every example, during both training and serving.\n",
    "2. **TensorFlow Transform Analyzers:** Any of the analyzers provided by tf.Transform. Analyzers also accept and return tensors, but unlike TensorFlow ops they only run once, during training, and typically make a full pass over the entire training dataset. They create [tensor constants](https://www.tensorflow.org/versions/r1.15/api_docs/python/tf/constant), which are added to your graph. For example, `tft.min` computes the minimum of a tensor over the training dataset. tf.Transform provides a fixed set of analyzers, but this will be extended in future versions.\n",
    "\n",
    "Caution: When you apply your preprocessing function to serving inferences, the constants that were created by analyzers during training do not change.  If your data has trend or seasonality components, plan accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/tensorflow/transform/blob/3375730685445d1f8b3b6a696c851087bb6b6441/examples/sentiment_example.py\n",
    "\n",
    "def preprocessing_fn(inputs):\n",
    "    \"\"\"Preprocess input columns into transformed columns.\"\"\"\n",
    "    review = inputs[REVIEW_KEY]\n",
    "\n",
    "    # Here tf.compat.v1.string_split behaves differently from\n",
    "    # tf.strings.split.\n",
    "    review_tokens = tf.compat.v1.string_split(review, DELIMITERS)\n",
    "    review_indices = tft.compute_and_apply_vocabulary(\n",
    "        review_tokens, top_k=VOCAB_SIZE)\n",
    "    # Add one for the oov bucket created by compute_and_apply_vocabulary.\n",
    "    review_bow_indices, review_weight = tft.tfidf(review_indices,\n",
    "                                                  VOCAB_SIZE + 1)\n",
    "    return {\n",
    "        REVIEW_KEY: review_bow_indices,\n",
    "        REVIEW_WEIGHT_KEY: review_weight,\n",
    "        LABEL_KEY: inputs[LABEL_KEY]\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rgAGOAdFWRn2"
   },
   "source": [
    "### Transform the data\n",
    "Now we're ready to start transforming our data in an Apache Beam pipeline.\n",
    "\n",
    "1. Read in the data using the CSV reader\n",
    "1. Transform it using a preprocessing pipeline that scales numeric data and converts categorical data from strings to int64 values indices, by creating a vocabulary for each category\n",
    "1. Write out the result as a `TFRecord` of `Example` protos, which we will use for training a model later\n",
    "\n",
    "<aside class=\"key-term\"><b>Key Term:</b> <a target='_blank' href='https://beam.apache.org/'>Apache Beam</a> uses a <a target='_blank' href='https://beam.apache.org/documentation/programming-guide/#applying-transforms'>special syntax to define and invoke transforms</a>.  For example, in this line:\n",
    "\n",
    "<code><blockquote>result = pass_this | 'name this step' >> to_this_call</blockquote></code>\n",
    "\n",
    "The method <code>to_this_call</code> is being invoked and passed the object called <code>pass_this</code>, and <a target='_blank' href='https://stackoverflow.com/questions/50519662/what-does-the-redirection-mean-in-apache-beam-python'>this operation will be referred to as <code>name this step</code> in a stack trace</a>.  The result of the call to <code>to_this_call</code> is returned in <code>result</code>.  You will often see stages of a pipeline chained together like this:\n",
    "\n",
    "<code><blockquote>result = apache_beam.Pipeline() | 'first step' >> do_this_first() | 'second step' >> do_this_last()</blockquote></code>\n",
    "\n",
    "and since that started with a new pipeline, you can continue like this:\n",
    "\n",
    "<code><blockquote>next_result = result | 'doing more stuff' >> another_function()</blockquote></code></aside>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BQAPzdCRwi5d"
   },
   "outputs": [],
   "source": [
    "def transform_data(train_data_file, test_data_file, working_dir):\n",
    "  \"\"\"Transform the data and write out as a TFRecord of Example protos.\n",
    "\n",
    "  Read in the data using the CSV reader, and transform it using \n",
    "  a preprocessing pipeline that removes punctuation, tokenizes \n",
    "  and maps tokens to int64 values indices.\n",
    "\n",
    "  Args:\n",
    "    train_data_file: File containing training data\n",
    "    test_data_file: File containing test data\n",
    "    working_dir: Directory to write transformed data and metadata to\n",
    "  \"\"\"\n",
    "\n",
    "  # The \"with\" block will create a pipeline, and run that pipeline at the exit\n",
    "  # of the block.\n",
    "  with beam.Pipeline() as pipeline:\n",
    "    with tft_beam.Context(temp_dir=tempfile.mkdtemp()):\n",
    "      # Create a coder to read the imdb data with the schema.  To do this we\n",
    "      # need to list all columns in order since the schema doesn't specify the\n",
    "      # order of columns in the csv.\n",
    "      ordered_columns = ['text', 'label']\n",
    "      converter = tft.coders.CsvCoder(ordered_columns, RAW_DATA_METADATA.schema)\n",
    "\n",
    "      # Read in raw data and convert using CSV converter.  Note that we apply\n",
    "      # some Beam transformations here, which will not be encoded in the TF\n",
    "      # graph since we don't do them from within tf.Transform's methods\n",
    "      # (AnalyzeDataset, TransformDataset etc.).  These transformations are just\n",
    "      # to get data into a format that the CSV converter can read, in particular\n",
    "      # removing spaces after commas.\n",
    "      raw_data = (\n",
    "          pipeline\n",
    "          | 'ReadTrainData' >> beam.io.ReadFromText(train_data_file, skip_header_lines=1)\n",
    "          | 'FixCommasTrainData' >> beam.Map(\n",
    "              lambda line: line.replace(', ', ','))\n",
    "          | 'DecodeTrainData' >> beam.Map(converter.decode)\n",
    "      )\n",
    "\n",
    "      # Combine data and schema into a dataset tuple.  Note that we already used\n",
    "      # the schema to read the CSV data, but we also need it to interpret\n",
    "      # raw_data.\n",
    "      raw_dataset = (raw_data, RAW_DATA_METADATA)\n",
    "      transformed_dataset, transform_fn = (\n",
    "          raw_dataset | tft_beam.AnalyzeAndTransformDataset(preprocessing_fn))\n",
    "      transformed_data, transformed_metadata = transformed_dataset\n",
    "      transformed_data_coder = tft.coders.ExampleProtoCoder(\n",
    "          transformed_metadata.schema)\n",
    "\n",
    "      _ = (\n",
    "          transformed_data\n",
    "          | 'EncodeTrainData' >> beam.Map(transformed_data_coder.encode)\n",
    "          | 'WriteTrainData' >> beam.io.WriteToTFRecord(\n",
    "              os.path.join(working_dir, TRANSFORMED_TRAIN_DATA_FILEBASE)))\n",
    "\n",
    "      # Now apply transform function to test data.  In this case we remove the\n",
    "      # trailing period at the end of each line, and also ignore the header line\n",
    "      # that is present in the test data file.\n",
    "      raw_test_data = (\n",
    "          pipeline\n",
    "          | 'ReadTestData' >> beam.io.ReadFromText(test_data_file,\n",
    "                                                   skip_header_lines=1)\n",
    "          | 'FixCommasTestData' >> beam.Map(\n",
    "              lambda line: line.replace(', ', ','))\n",
    "          | 'DecodeTestData' >> beam.Map(converter.decode)\n",
    "      )\n",
    "\n",
    "      raw_test_dataset = (raw_test_data, RAW_DATA_METADATA)\n",
    "\n",
    "      transformed_test_dataset = (\n",
    "          (raw_test_dataset, transform_fn) | tft_beam.TransformDataset())\n",
    "      # Don't need transformed data schema, it's the same as before.\n",
    "      transformed_test_data, _ = transformed_test_dataset\n",
    "\n",
    "      _ = (\n",
    "          transformed_test_data\n",
    "          | 'EncodeTestData' >> beam.Map(transformed_data_coder.encode)\n",
    "          | 'WriteTestData' >> beam.io.WriteToTFRecord(\n",
    "              os.path.join(working_dir, TRANSFORMED_TEST_DATA_FILEBASE)))\n",
    "\n",
    "      # Will write a SavedModel and metadata to working_dir, which can then\n",
    "      # be read by the tft.TFTransformOutput class.\n",
    "      _ = (\n",
    "          transform_fn\n",
    "          | 'WriteTransformFn' >> tft_beam.WriteTransformFn(working_dir))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TnaMyRMJ03bR"
   },
   "source": [
    "## Using our preprocessed data to train a model\n",
    "\n",
    "To show how `tf.Transform` enables us to use the same code for both training and serving, and thus prevent skew, we're going to train a model.  To train our model and prepare our trained model for production we need to create input functions.  The main difference between our training input function and our serving input function is that training data contains the labels, and production data does not.  The arguments and returns are also somewhat different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M8xCZKNc2wAS"
   },
   "source": [
    "### Create an input function for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kFO0MeWQ228a"
   },
   "outputs": [],
   "source": [
    "def _make_training_input_fn(tf_transform_output, transformed_examples,\n",
    "                            batch_size):\n",
    "  \"\"\"Creates an input function reading from transformed data.\n",
    "\n",
    "  Args:\n",
    "    tf_transform_output: Wrapper around output of tf.Transform.\n",
    "    transformed_examples: Base filename of examples.\n",
    "    batch_size: Batch size.\n",
    "\n",
    "  Returns:\n",
    "    The input function for training or eval.\n",
    "  \"\"\"\n",
    "  def input_fn():\n",
    "    \"\"\"Input function for training and eval.\"\"\"\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=transformed_examples,\n",
    "        batch_size=batch_size,\n",
    "        features=tf_transform_output.transformed_feature_spec(),\n",
    "        reader=tf.data.TFRecordDataset,\n",
    "        shuffle=True)\n",
    "\n",
    "    transformed_features = tf.compat.v1.data.make_one_shot_iterator(\n",
    "        dataset).get_next()\n",
    "\n",
    "    # Extract features and label from the transformed tensors.\n",
    "    transformed_labels = transformed_features.pop(LABEL_KEY)\n",
    "\n",
    "    return transformed_features, transformed_labels\n",
    "\n",
    "  return input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nYeuthrs27vl"
   },
   "source": [
    "### Create an input function for serving\n",
    "\n",
    "Let's create an input function that we could use in production, and prepare our trained model for serving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NN5FVg343Jea"
   },
   "outputs": [],
   "source": [
    "def _make_serving_input_fn(tf_transform_output):\n",
    "  \"\"\"Creates an input function reading from raw data.\n",
    "\n",
    "  Args:\n",
    "    tf_transform_output: Wrapper around output of tf.Transform.\n",
    "\n",
    "  Returns:\n",
    "    The serving input function.\n",
    "  \"\"\"\n",
    "  raw_feature_spec = RAW_DATA_FEATURE_SPEC.copy()\n",
    "  # Remove label since it is not available during serving.\n",
    "  raw_feature_spec.pop(LABEL_KEY)\n",
    "\n",
    "  def serving_input_fn():\n",
    "    \"\"\"Input function for serving.\"\"\"\n",
    "    # Get raw features by generating the basic serving input_fn and calling it.\n",
    "    # Here we generate an input_fn that expects a parsed Example proto to be fed\n",
    "    # to the model at serving time.  See also\n",
    "    # tf.estimator.export.build_raw_serving_input_receiver_fn.\n",
    "    raw_input_fn = tf.estimator.export.build_parsing_serving_input_receiver_fn(\n",
    "        raw_feature_spec, default_batch_size=None)\n",
    "    serving_input_receiver = raw_input_fn()\n",
    "\n",
    "    # Apply the transform function that was used to generate the materialized\n",
    "    # data.\n",
    "    raw_features = serving_input_receiver.features\n",
    "    transformed_features = tf_transform_output.transform_raw_features(\n",
    "        raw_features)\n",
    "\n",
    "    return tf.estimator.export.ServingInputReceiver(\n",
    "        transformed_features, serving_input_receiver.receiver_tensors)\n",
    "\n",
    "  return serving_input_fn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vc9Edp8A7dsI"
   },
   "source": [
    "### Wrap our input data in FeatureColumns\n",
    "Our model will expect our data in TensorFlow FeatureColumns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_columns(tf_transform_output):\n",
    "  \"\"\"Returns the FeatureColumns for the model.\n",
    "  Args:\n",
    "    tf_transform_output: A `TFTransformOutput` object.\n",
    "  Returns:\n",
    "    A list of FeatureColumns.\n",
    "  \"\"\"\n",
    "  del tf_transform_output  # unused\n",
    "  # Unrecognized tokens are represented by -1, but\n",
    "  # categorical_column_with_identity uses the mod operator to map integers\n",
    "  # to the range [0, bucket_size).  By choosing bucket_size=VOCAB_SIZE + 1, we\n",
    "  # represent unrecognized tokens as VOCAB_SIZE.\n",
    "  review_column = tf.feature_column.categorical_column_with_identity(\n",
    "      REVIEW_KEY, num_buckets=VOCAB_SIZE + 1)\n",
    "  weighted_reviews = tf.feature_column.weighted_categorical_column(\n",
    "      review_column, REVIEW_WEIGHT_KEY)\n",
    "\n",
    "  return [weighted_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LyNTX7CO8AAz"
   },
   "source": [
    "## Train, Evaluate, and Export our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8iGQ0jeq8IWr"
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate(working_dir, num_train_instances=NUM_TRAIN_INSTANCES,\n",
    "                       num_test_instances=NUM_TEST_INSTANCES):\n",
    "  \"\"\"Train the model on training data and evaluate on test data.\n",
    "\n",
    "  Args:\n",
    "    working_dir: Directory to read transformed data and metadata from and to\n",
    "        write exported model to.\n",
    "    num_train_instances: Number of instances in train set\n",
    "    num_test_instances: Number of instances in test set\n",
    "\n",
    "  Returns:\n",
    "    The results from the estimator's 'evaluate' method\n",
    "  \"\"\"\n",
    "  tf_transform_output = tft.TFTransformOutput(working_dir)\n",
    "\n",
    "  run_config = tf.estimator.RunConfig()\n",
    "\n",
    "  estimator = tf.estimator.LinearClassifier(\n",
    "      feature_columns=get_feature_columns(tf_transform_output),\n",
    "      config=run_config,\n",
    "      loss_reduction=tf.losses.Reduction.SUM)\n",
    "\n",
    "  # Fit the model using the default optimizer.\n",
    "  train_input_fn = _make_training_input_fn(\n",
    "      tf_transform_output,\n",
    "      os.path.join(working_dir, TRANSFORMED_TRAIN_DATA_FILEBASE + '*'),\n",
    "      batch_size=TRAIN_BATCH_SIZE)\n",
    "  estimator.train(\n",
    "      input_fn=train_input_fn,\n",
    "      max_steps=TRAIN_NUM_EPOCHS * num_train_instances / TRAIN_BATCH_SIZE)\n",
    "\n",
    "  # Evaluate model on test dataset.\n",
    "  eval_input_fn = _make_training_input_fn(\n",
    "      tf_transform_output,\n",
    "      os.path.join(working_dir, TRANSFORMED_TEST_DATA_FILEBASE + '*'),\n",
    "      batch_size=1)\n",
    "\n",
    "  # Export the model.\n",
    "  serving_input_fn = _make_serving_input_fn(tf_transform_output)\n",
    "  exported_model_dir = os.path.join(working_dir, EXPORTED_MODEL_DIR)\n",
    "  estimator.export_saved_model(exported_model_dir, serving_input_fn)\n",
    "\n",
    "  return estimator.evaluate(input_fn=eval_input_fn, steps=num_test_instances)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JrFJ9Zax8QAh"
   },
   "source": [
    "## Put it all together\n",
    "We've created all the stuff we need to preprocess our imdb data, train a model, and prepare it for serving.  So far we've just been getting things ready.  It's time to start running!\n",
    "\n",
    "Note: Scroll the output from this cell to see the whole process.  The results will be at the bottom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xe7JdSin86Ez",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\the\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_tfx\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\the\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_tfx\\lib\\site-packages\\tensorflow_core\\python\\saved_model\\signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\2c241122c30847f290780b6ab9ff58ec\\saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\2c241122c30847f290780b6ab9ff58ec\\saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\2897f5dbb50a46a4b141fac50c08c0dd\\saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\2897f5dbb50a46a4b141fac50c08c0dd\\saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:No assets to write.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Issue encountered when serializing tft_mapper_use.\n",
      "Type is unsupported, or the types of the items don't match field type in CollectionDef. Note this is a warning and probably safe to ignore.\n",
      "'Counter' object has no attribute 'name'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\26512e211c7a442e9bfa16d67111976e\\saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\26512e211c7a442e9bfa16d67111976e\\saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Tensorflow version (2.1.0) found. Note that Tensorflow Transform support for TF 2.0 is currently in beta, and features such as tf.function may not work as intended. \n",
      "WARNING:apache_beam.utils.interactive_utils:Failed to alter the label of a transform with the ipython prompt metadata. Cannot figure out the pipeline that the given pvalueish ((<PCollection[DecodeTestData.None] at 0x193472aa948>, {'_schema': feature {\n",
      "  name: \"label\"\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"text\"\n",
      "  type: BYTES\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "}), (<PCollection[AnalyzeAndTransformDataset/AnalyzeDataset/CreateSavedModel/BindTensors/ReplaceWithConstants.None] at 0x193476de848>, BeamDatasetMetadata(dataset_metadata={'_schema': feature {\n",
      "  name: \"label\"\n",
      "  type: INT\n",
      "  presence {\n",
      "    min_fraction: 1.0\n",
      "  }\n",
      "  shape {\n",
      "  }\n",
      "}\n",
      "feature {\n",
      "  name: \"review_weight\"\n",
      "  type: FLOAT\n",
      "}\n",
      "feature {\n",
      "  name: \"text\"\n",
      "  type: INT\n",
      "}\n",
      "}, deferred_metadata=<PCollection[AnalyzeAndTransformDataset/AnalyzeDataset/ComputeDeferredMetadata.None] at 0x194d3fcf608>))) belongs to. Thus noop.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\35283e82bcef484aaf5f43d9aebfc2bc\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\35283e82bcef484aaf5f43d9aebfc2bc\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\35283e82bcef484aaf5f43d9aebfc2bc\\saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\35283e82bcef484aaf5f43d9aebfc2bc\\saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got [type.googleapis.com/tensorflow.AssetFileDef] {\n",
      "  tensor_info {\n",
      "    name: \"Const_1:0\"\n",
      "  }\n",
      "  filename: \"vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got [type.googleapis.com/tensorflow.AssetFileDef] {\n",
      "  tensor_info {\n",
      "    name: \"Const_1:0\"\n",
      "  }\n",
      "  filename: \"vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\7d943ea3f4c54507a4bf2fea145855f0\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\7d943ea3f4c54507a4bf2fea145855f0\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\7d943ea3f4c54507a4bf2fea145855f0\\saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: C:\\Users\\the\\AppData\\Local\\Temp\\tmpdagu9i60\\tftransform_tmp\\7d943ea3f4c54507a4bf2fea145855f0\\saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got [type.googleapis.com/tensorflow.AssetFileDef] {\n",
      "  tensor_info {\n",
      "    name: \"Const_1:0\"\n",
      "  }\n",
      "  filename: \"vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got [type.googleapis.com/tensorflow.AssetFileDef] {\n",
      "  tensor_info {\n",
      "    name: \"Const_1:0\"\n",
      "  }\n",
      "  filename: \"vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got [type.googleapis.com/tensorflow.AssetFileDef] {\n",
      "  tensor_info {\n",
      "    name: \"Const_1:0\"\n",
      "  }\n",
      "  filename: \"vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got [type.googleapis.com/tensorflow.AssetFileDef] {\n",
      "  tensor_info {\n",
      "    name: \"Const_1:0\"\n",
      "  }\n",
      "  filename: \"vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:apache_beam.io.tfrecordio:Couldn't find python-snappy so the implementation of _TFRecordUtil._masked_crc32c is not as fast as it could be.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got [type.googleapis.com/tensorflow.AssetFileDef] {\n",
      "  tensor_info {\n",
      "    name: \"Const_1:0\"\n",
      "  }\n",
      "  filename: \"vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got [type.googleapis.com/tensorflow.AssetFileDef] {\n",
      "  tensor_info {\n",
      "    name: \"Const_1:0\"\n",
      "  }\n",
      "  filename: \"vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\the\\\\AppData\\\\Local\\\\Temp\\\\tmpymyz76xi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\the\\\\AppData\\\\Local\\\\Temp\\\\tmpymyz76xi', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\the\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_tfx\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\the\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_tfx\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1635: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\the\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_tfx\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\the\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_tfx\\lib\\site-packages\\tensorflow_core\\python\\training\\training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\the\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_tfx\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\the\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_tfx\\lib\\site-packages\\tensorflow_core\\python\\feature_column\\feature_column_v2.py:518: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\users\\the\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_tfx\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\the\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_tfx\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "WARNING:tensorflow:From c:\\users\\the\\appdata\\local\\continuum\\anaconda3\\envs\\tensorflow_tfx\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\ftrl.py:143: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 0 into C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 88.72284, step = 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 88.72284, step = 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 94.102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 94.102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 75.59761, step = 100 (1.065 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 75.59761, step = 100 (1.065 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 107.028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 107.028\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 65.89246, step = 200 (0.935 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 65.89246, step = 200 (0.935 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 107.576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 107.576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 61.948456, step = 300 (0.929 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 61.948456, step = 300 (0.929 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 103.643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 103.643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 57.806564, step = 400 (0.966 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 57.806564, step = 400 (0.966 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 106.313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 106.313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 55.763664, step = 500 (0.940 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 55.763664, step = 500 (0.940 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 112.736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 112.736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 56.44605, step = 600 (0.888 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 56.44605, step = 600 (0.888 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 54.172916, step = 700 (0.860 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 54.172916, step = 700 (0.860 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 50.458836, step = 800 (0.874 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 50.458836, step = 800 (0.874 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 54.180107, step = 900 (0.861 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 54.180107, step = 900 (0.861 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 113.178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 113.178\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 53.16276, step = 1000 (0.884 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 53.16276, step = 1000 (0.884 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 48.398293, step = 1100 (0.873 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 48.398293, step = 1100 (0.873 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 44.181213, step = 1200 (0.865 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 44.181213, step = 1200 (0.865 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.959\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 45.790894, step = 1300 (0.853 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 45.790894, step = 1300 (0.853 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 47.93828, step = 1400 (0.864 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 47.93828, step = 1400 (0.864 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 113.803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 113.803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 41.588318, step = 1500 (0.880 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 41.588318, step = 1500 (0.880 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 113.809\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 113.809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 52.57949, step = 1600 (0.878 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 52.57949, step = 1600 (0.878 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 45.040047, step = 1700 (0.874 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 45.040047, step = 1700 (0.874 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 45.69735, step = 1800 (0.862 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 45.69735, step = 1800 (0.862 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.684\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 38.66687, step = 1900 (0.872 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 38.66687, step = 1900 (0.872 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 117.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 117.024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 43.128967, step = 2000 (0.856 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 43.128967, step = 2000 (0.856 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 37.956184, step = 2100 (0.871 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 37.956184, step = 2100 (0.871 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 109.213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 109.213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 41.78333, step = 2200 (0.916 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 41.78333, step = 2200 (0.916 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 113.234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 113.234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 38.69662, step = 2300 (0.883 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 38.69662, step = 2300 (0.883 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 42.41269, step = 2400 (0.869 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 42.41269, step = 2400 (0.869 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 38.093376, step = 2500 (0.867 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 38.093376, step = 2500 (0.867 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.813\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 36.024292, step = 2600 (0.871 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 36.024292, step = 2600 (0.871 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 117.152\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 117.152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 41.055367, step = 2700 (0.854 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 41.055367, step = 2700 (0.854 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 117.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 117.379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 36.75254, step = 2800 (0.852 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 36.75254, step = 2800 (0.852 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 108.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 108.46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 50.256046, step = 2900 (0.922 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 50.256046, step = 2900 (0.922 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.379\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 34.87541, step = 3000 (0.867 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 34.87541, step = 3000 (0.867 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 113.159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 113.159\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 42.128975, step = 3100 (0.885 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 42.128975, step = 3100 (0.885 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.502\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 38.17366, step = 3200 (0.857 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 38.17366, step = 3200 (0.857 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 39.303467, step = 3300 (0.860 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 39.303467, step = 3300 (0.860 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 42.635345, step = 3400 (0.869 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 42.635345, step = 3400 (0.869 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.685\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 116.685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 35.69165, step = 3500 (0.857 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 35.69165, step = 3500 (0.857 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 117.094\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 117.094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 30.901636, step = 3600 (0.854 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 30.901636, step = 3600 (0.854 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 107.088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 107.088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 34.713566, step = 3700 (0.934 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 34.713566, step = 3700 (0.934 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 115.205\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 36.199425, step = 3800 (0.868 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 36.199425, step = 3800 (0.868 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 114.683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 32.81576, step = 3900 (0.873 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 32.81576, step = 3900 (0.873 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 111.982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 111.982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 30.346886, step = 4000 (0.892 sec)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 30.346886, step = 4000 (0.892 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4071 into C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\\model.ckpt.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 4071 into C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\\model.ckpt.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 36.533607.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Loss for final step: 36.533607.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got [type.googleapis.com/tensorflow.AssetFileDef] {\n",
      "  tensor_info {\n",
      "    name: \"Const_1:0\"\n",
      "  }\n",
      "  filename: \"vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Expected binary or unicode string, got [type.googleapis.com/tensorflow.AssetFileDef] {\n",
      "  tensor_info {\n",
      "    name: \"Const_1:0\"\n",
      "  }\n",
      "  filename: \"vocab_compute_and_apply_vocabulary_vocabulary\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Classify: ['serving_default', 'classification']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['regression']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Regress: ['regression']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Predict: ['predict']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Train: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Signatures INCLUDED in export for Eval: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\\model.ckpt-4071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\\model.ckpt-4071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets added to graph.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exported_model_dir\\temp-b'1591341342'\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: exported_model_dir\\temp-b'1591341342'\\assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: exported_model_dir\\temp-b'1591341342'\\saved_model.pb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:SavedModel written to: exported_model_dir\\temp-b'1591341342'\\saved_model.pb\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done calling model_fn.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-06-05T09:15:43Z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2020-06-05T09:15:43Z\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Graph was finalized.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\\model.ckpt-4071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\\model.ckpt-4071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Done running local_init_op.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1628/16281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [1628/16281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3256/16281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [3256/16281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4884/16281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [4884/16281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [6512/16281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [6512/16281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [8140/16281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [8140/16281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [9768/16281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [9768/16281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [11396/16281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [11396/16281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [13024/16281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [13024/16281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [14652/16281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [14652/16281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [16280/16281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [16280/16281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [16281/16281]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Evaluation [16281/16281]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 91.83177s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Inference Time : 91.83177s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-06-05-09:17:15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished evaluation at 2020-06-05-09:17:15\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 4071: accuracy = 0.9137031, accuracy_baseline = 0.5011363, auc = 0.97100824, auc_precision_recall = 0.9701615, average_loss = 0.28369084, global_step = 4071, label/mean = 0.5011363, loss = 0.28369084, precision = 0.91152817, prediction/mean = 0.4994619, recall = 0.91677904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving dict for global step 4071: accuracy = 0.9137031, accuracy_baseline = 0.5011363, auc = 0.97100824, auc_precision_recall = 0.9701615, average_loss = 0.28369084, global_step = 4071, label/mean = 0.5011363, loss = 0.28369084, precision = 0.91152817, prediction/mean = 0.4994619, recall = 0.91677904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4071: C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\\model.ckpt-4071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 4071: C:\\Users\\the\\AppData\\Local\\Temp\\tmpymyz76xi\\model.ckpt-4071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'accuracy': 0.9137031,\n",
      " 'accuracy_baseline': 0.5011363,\n",
      " 'auc': 0.97100824,\n",
      " 'auc_precision_recall': 0.9701615,\n",
      " 'average_loss': 0.28369084,\n",
      " 'global_step': 4071,\n",
      " 'label/mean': 0.5011363,\n",
      " 'loss': 0.28369084,\n",
      " 'precision': 0.91152817,\n",
      " 'prediction/mean': 0.4994619,\n",
      " 'recall': 0.91677904}\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "temp = tempfile.gettempdir()\n",
    "\n",
    "transform_data(train, test, \"\")\n",
    "results = train_and_evaluate(\"\")\n",
    "pprint.pprint(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ICqetCnSjwp1"
   },
   "source": [
    "## What we did  \n",
    "\n",
    "In this example we used `tf.Transform` to preprocess a dataset of imdb data, and train a model with the cleaned and transformed data.  We also created an input function that we could use when we deploy our trained model in a production environment to perform inference.  By using the same code for both training and inference we avoid any issues with data skew.  Along the way we learned about creating an Apache Beam transform to perform the transformation that we needed for cleaning the data, and wrapped our data in TensorFlow `FeatureColumns`.  This is just a small piece of what TensorFlow Transform can do!  We encourage you to dive into `tf.Transform` and discover what it can do for you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Serving The Model\n",
    "\n",
    "Serving the model can be done using TFX serving using docker https://www.tensorflow.org/tfx/serving/docker\n",
    "This way you can serve the model with a RESTfull interface or even with a gRPC interface.\n",
    "\n",
    "The greatest benefit of using TFX and TFX serving from my point of view is that you are adding the transformations into the compute graph, this means that when serving you dont need to keep track of the word tokenizer of your category encodings, you call the API with Text, and you get back the category names\n",
    "\n",
    "### Preparing\n",
    "I tested this on my local windows machine, and here you need to\n",
    "1. install docker https://docs.docker.com/docker-for-windows/install/\n",
    "1. Make sure you have shared the path where you model is saved i moved it to c:/temp  \n",
    "    Open Docker Desktop  \n",
    "    Go to Settings  \n",
    "    Go to Resources  \n",
    "    Go to Filesharing  \n",
    "    Add the path to your model  \n",
    "\n",
    "### Serving\n",
    "Run the Serving container and mounting the model, TFX serving will pick up the model and serve it at rest endpoint at port 8501\n",
    "\n",
    "`docker run -p 8501:8501 --mount type=bind,source=c:\\temp\\exported_model_dir,target=/models/imdb -e MODEL_NAME=imdb -t tensorflow/serving &`\n",
    "\n",
    "### Classifying\n",
    "Call up endpoint http://localhost:8501/v1/models/imdb:classify\n",
    "\n",
    "with payload\n",
    "`{\"examples\":[{\"text\":\"greatest movie i ever seen\"}]}`\n",
    "\n",
    "I use postman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "census.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
